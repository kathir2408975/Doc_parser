{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556b0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9838b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "\n",
    "pdf_path = r\"C:\\kathir\\all_file_1\\temp_1.pdf\"\n",
    "output_dir = r\"C:\\kathir\\all_file_1\\output_new_approach\"\n",
    "\n",
    "images_dir = os.path.join(output_dir, \"images\")\n",
    "graphs_dir = os.path.join(output_dir, \"graphs\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(graphs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26a83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sequence = []\n",
    "\n",
    "# === [STEP 1] PROCESS WITH PyMuPDF ===\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc[page_num]\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "    # --- TEXT BLOCKS (Column-wise) ---\n",
    "    left_column = []\n",
    "    right_column = []\n",
    "    column_split_x = page.rect.width / 2\n",
    "\n",
    "    for block in blocks:\n",
    "        if block[\"type\"] != 0:\n",
    "            continue\n",
    "        x0 = block[\"bbox\"][0]\n",
    "        y0 = block[\"bbox\"][1]\n",
    "        text = \"\"\n",
    "        for line in block[\"lines\"]:\n",
    "            for span in line[\"spans\"]:\n",
    "                text += span[\"text\"] + \" \"\n",
    "        text = text.strip()\n",
    "\n",
    "        if x0 < column_split_x:\n",
    "            left_column.append((y0, text))\n",
    "        else:\n",
    "            right_column.append((y0, text))\n",
    "\n",
    "    left_column.sort(key=lambda x: x[0])\n",
    "    right_column.sort(key=lambda x: x[0])\n",
    "    sorted_blocks = left_column + right_column\n",
    "\n",
    "    for i, (_, text) in enumerate(sorted_blocks):\n",
    "        output_sequence.append(f\"[Text Page {page_num + 1} Block {i + 1}]\\n{text}\")\n",
    "\n",
    "    # --- RASTER IMAGE EXTRACTION (normal images only) ---\n",
    "    image_list = page.get_images(full=True)\n",
    "    for img_index, img in enumerate(image_list):\n",
    "        xref = img[0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        image_ext = base_image[\"ext\"]\n",
    "        image_filename = f\"page_{page_num + 1}_img_{img_index + 1}.{image_ext}\"\n",
    "        image_path = os.path.join(images_dir, image_filename)\n",
    "\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(image_bytes)\n",
    "\n",
    "        output_sequence.append(f\"[Image Page {page_num + 1} Image {img_index + 1}] -> {image_path}\")\n",
    "\n",
    "    # --- CROP GRAPHS USING OPENCV ---\n",
    "    zoom = 4\n",
    "    mat = fitz.Matrix(zoom, zoom)\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    img_path = os.path.join(output_dir, f\"temp_page_{page_num + 1}.png\")\n",
    "    pix.save(img_path)\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask_red = cv2.inRange(hsv, (0, 50, 50), (10, 255, 255))\n",
    "    mask_blue = cv2.inRange(hsv, (100, 150, 0), (140, 255, 255))\n",
    "    mask_yellow = cv2.inRange(hsv, (20, 100, 100), (30, 255, 255))\n",
    "    mask_green = cv2.inRange(hsv, (40, 40, 40), (80, 255, 255))\n",
    "\n",
    "    color_mask = cv2.bitwise_or(mask_red, mask_blue)\n",
    "    color_mask = cv2.bitwise_or(color_mask, mask_yellow)\n",
    "    color_mask = cv2.bitwise_or(color_mask, mask_green)\n",
    "\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    dilated_mask = cv2.dilate(color_mask, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(dilated_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w < 200 or h < 200 or w / h > 5 or h / w > 5:\n",
    "            continue\n",
    "        cropped = image[y:y+h, x:x+w]\n",
    "        graph_filename = f\"page_{page_num+1}_graph_{i+1}.png\"\n",
    "        graph_path = os.path.join(graphs_dir, graph_filename)\n",
    "        cv2.imwrite(graph_path, cropped)\n",
    "        output_sequence.append(f\"[Graph Page {page_num + 1} Graph {i + 1}] -> {graph_path}\")\n",
    "\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699aa987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extraction Complete!\n",
      "Text: C:\\kathir\\all_file_1\\output_new_approach\\pdf_extracted_output.txt\n",
      "Images: C:\\kathir\\all_file_1\\output_new_approach\\images\n",
      "Graphs: C:\\kathir\\all_file_1\\output_new_approach\\graphs\n"
     ]
    }
   ],
   "source": [
    "# === [STEP 2] TABLE EXTRACTION ===\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        tables = page.extract_tables()\n",
    "        for t_index, table in enumerate(tables, start=1):\n",
    "            output_sequence.append(f\"[Table Page {page_num + 1} Table {t_index}]\")\n",
    "            for row in table:\n",
    "                output_sequence.append(\"\\t\".join(cell or \"\" for cell in row))\n",
    "\n",
    "# === [STEP 3] WRITE TEXT OUTPUT ===\n",
    "output_file = os.path.join(output_dir, \"pdf_extracted_output.txt\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in output_sequence:\n",
    "        f.write(item + \"\\n\\n\")\n",
    "\n",
    "print(f\"\\u2705 Extraction Complete!\\nText: {output_file}\\nImages: {images_dir}\\nGraphs: {graphs_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6fd52",
   "metadata": {},
   "source": [
    "##version 1 - scanned pdf checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b0579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PyPDF2 import PdfReader\n",
    "# from docx import Document\n",
    "\n",
    "# def check_pdf_type(pdf_path):\n",
    "#     try:\n",
    "#         reader = PdfReader(pdf_path)\n",
    "#         for page in reader.pages:\n",
    "#             text = page.extract_text()\n",
    "#             if text and text.strip():\n",
    "#                 return \"unscanned\"\n",
    "#         return \"scanned\"\n",
    "#     except Exception as e:\n",
    "#         return f\"error ({e})\"\n",
    "\n",
    "# def check_doc_type(doc_path):\n",
    "#     try:\n",
    "#         doc = Document(doc_path)\n",
    "#         for para in doc.paragraphs:\n",
    "#             if para.text.strip():\n",
    "#                 return \"unscanned\"\n",
    "#         return \"scanned\"\n",
    "#     except Exception as e:\n",
    "#         return f\"error ({e})\"\n",
    "\n",
    "# def check_file_type(file_path):\n",
    "#     ext = os.path.splitext(file_path)[1].lower()\n",
    "#     if ext == '.pdf':\n",
    "#         return check_pdf_type(file_path)\n",
    "#     elif ext in ['.doc', '.docx']:\n",
    "#         return check_doc_type(file_path)\n",
    "#     else:\n",
    "#         return \"skipped (unsupported type)\"\n",
    "\n",
    "# def check_all_files_in_directory(directory_path):\n",
    "#     for file_name in os.listdir(directory_path):\n",
    "#         file_path = os.path.join(directory_path, file_name)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             result = check_file_type(file_path)\n",
    "#             print(f\"{file_name}: {result}\")\n",
    "\n",
    "# # === USAGE ===\n",
    "# directory_path = r\"C:\\Users\\VMSKNLFST\\Documents\\GitHub\\Doc_parser\"  # Change this to your directory\n",
    "# check_all_files_in_directory(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
